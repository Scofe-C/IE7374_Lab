{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 3-1 — Weak Supervision: Labeling Functions for Email Classification\n\nIn this lab we use **Snorkel** to programmatically label a dataset of emails as `PHISHING` or `LEGITIMATE` without hand-labeling the training set.\n\nThe core idea of weak supervision is to write **labeling functions (LFs)** — noisy heuristic rules that each vote on a label. Snorkel's `LabelModel` then combines these noisy votes into a single probabilistic label per data point, accounting for each LF's accuracy and correlations between them.",
   "id": "f558a26b197f99eb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Task: Phishing Email Detection\n\nWe classify email subjects and body text into two categories:\n- `LEGITIMATE` (0): normal work, personal, or transactional emails\n- `PHISHING` (1): emails attempting to deceive the recipient — fake urgency, prize scams, credential harvesting\n\nPhishing emails have distinctive linguistic patterns that make them well-suited for rule-based labeling functions.",
   "id": "194a7dd46916c2db"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Data Splits\n\nWe split into:\n- **Training set** (~70%): labels are withheld (`-1`). LFs will generate noisy labels for this set.\n- **Test set** (~30%): gold labels are kept for final evaluation.",
   "id": "8e5962b2c12d6ae3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Setup and Loading Data",
   "id": "5260cc3b7a8f179a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:32:17.826015700Z",
     "start_time": "2026-02-24T03:32:17.394690300Z"
    }
   },
   "source": "import os\nimport random\nimport numpy as np\nimport pandas as pd\n\n# Reproducibility\nrandom.seed(42)\nnp.random.seed(42)\n\npd.set_option(\"display.max_colwidth\", 80)",
   "id": "1bb04bd949263805",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:12.586699800Z",
     "start_time": "2026-02-24T03:34:12.537823400Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"emails.csv\")\n",
    "\n",
    "# Train set: drop labels (simulate unlabeled data)\n",
    "# Test set: keep gold labels for evaluation\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.3, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "df_train = df_train_full.copy()\n",
    "Y_test = df_test[\"label\"].values\n",
    "Y_train_gold = df_train_full[\"label\"].values  # keep for final comparison only\n",
    "\n",
    "# Hide training labels — this is what weak supervision works with\n",
    "df_train[\"label\"] = -1\n",
    "\n",
    "print(f\"Training set: {len(df_train)} emails (labels hidden)\")\n",
    "print(f\"Test set:     {len(df_test)} emails (gold labels kept)\")\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(df_test[\"label\"].value_counts().rename({0: 'LEGITIMATE', 1: 'PHISHING'}))"
   ],
   "id": "579a84aa934cf5b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 56 emails (labels hidden)\n",
      "Test set:     24 emails (gold labels kept)\n",
      "\n",
      "Test set class distribution:\n",
      "label\n",
      "LEGITIMATE    12\n",
      "PHISHING      12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Exploring the Training Data\n\nBefore writing LFs, always look at a sample to develop intuition about what patterns distinguish the classes.",
   "id": "ffc3c03de1f05dd2"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:19.017760500Z",
     "start_time": "2026-02-24T03:34:18.974215400Z"
    }
   },
   "source": "# Look at a sample of the raw data\ndf_train[[\"subject\", \"body\"]].sample(10, random_state=7)",
   "id": "a3afa4a3c60738f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       subject  \\\n",
       "34         Your package could not be delivered   \n",
       "74             Act now: IRS tax refund pending   \n",
       "73   Security breach: change your password NOW   \n",
       "71           Confirm your email or lose access   \n",
       "28            RE: Transfer confirmation needed   \n",
       "19        Your PayPal account has been limited   \n",
       "3                   Re: design review feedback   \n",
       "27        Weekly engineering digest - Feb 2026   \n",
       "68  Python meetup this Thursday - register now   \n",
       "14             Lunch order - what do you want?   \n",
       "\n",
       "                                                                               body  \n",
       "34     Confirm your address and pay $1.99 redelivery fee at http://delivery-fix.net  \n",
       "74               You are owed $1,240. Submit your SSN to process your refund today.  \n",
       "73        We detected a breach. Reset your password immediately at http://reset.xyz  \n",
       "71           This is your last warning. Verify your email at http://confirm-now.biz  \n",
       "28                    Please confirm the $7,800 transfer by replying with your PIN.  \n",
       "19               Action required: confirm your identity at http://paypal-secure.xyz  \n",
       "3   Thanks for sharing the mockups! Left some comments in Figma - please take a ...  \n",
       "27      Here's your weekly summary of PRs merged, incidents, and upcoming releases.  \n",
       "68  Join us Thursday for talks on async Python and ML pipelines. Free registration.  \n",
       "14                    We're doing a group lunch order from Chipotle. Reply by noon.  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Your package could not be delivered</td>\n",
       "      <td>Confirm your address and pay $1.99 redelivery fee at http://delivery-fix.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Act now: IRS tax refund pending</td>\n",
       "      <td>You are owed $1,240. Submit your SSN to process your refund today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Security breach: change your password NOW</td>\n",
       "      <td>We detected a breach. Reset your password immediately at http://reset.xyz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Confirm your email or lose access</td>\n",
       "      <td>This is your last warning. Verify your email at http://confirm-now.biz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RE: Transfer confirmation needed</td>\n",
       "      <td>Please confirm the $7,800 transfer by replying with your PIN.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Your PayPal account has been limited</td>\n",
       "      <td>Action required: confirm your identity at http://paypal-secure.xyz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: design review feedback</td>\n",
       "      <td>Thanks for sharing the mockups! Left some comments in Figma - please take a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Weekly engineering digest - Feb 2026</td>\n",
       "      <td>Here's your weekly summary of PRs merged, incidents, and upcoming releases.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Python meetup this Thursday - register now</td>\n",
       "      <td>Join us Thursday for talks on async Python and ML pipelines. Free registration.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lunch order - what do you want?</td>\n",
       "      <td>We're doing a group lunch order from Chipotle. Reply by noon.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Observations from exploration\n\nLooking at the data, a few patterns stand out for phishing emails:\n- Urgent language: *immediately*, *urgent*, *act now*, *warning*, *alert*\n- Financial bait: *$*, *win*, *free*, *prize*, *cash*\n- ALL CAPS words in the subject line\n- URLs or link references in the body text\n- Requests for personal information: *verify*, *confirm*, *account number*, *SSN*\n\nLegitimate emails tend to:\n- Reference meetings, colleagues, schedules\n- Have standard professional language\n- Use `Re:` or `Fwd:` with real business context",
   "id": "f7f0c659056101f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Writing Labeling Functions\n\nLabeling functions take a single data point (a pandas row) and return:\n- `PHISHING` (1)\n- `LEGITIMATE` (0)\n- `ABSTAIN` (-1) — when the LF has no strong signal\n\nAbstaining is important — it is better for an LF to abstain than to make an incorrect guess.",
   "id": "718065d2012fd858"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:22.885700200Z",
     "start_time": "2026-02-24T03:34:22.849215500Z"
    }
   },
   "source": "import re\nfrom snorkel.labeling import labeling_function, LabelingFunction, PandasLFApplier, LFAnalysis\n\nABSTAIN = -1\nLEGITIMATE = 0\nPHISHING = 1",
   "id": "9345cd415732018d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### a) Keyword-based LFs",
   "id": "a4a85fab849c8486"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:24.622489300Z",
     "start_time": "2026-02-24T03:34:24.596619700Z"
    }
   },
   "source": "# Urgency language in subject or body\n@labeling_function()\ndef lf_urgent_keywords(x):\n    urgent = [\"urgent\", \"immediately\", \"act now\", \"right away\", \"last chance\", \"final notice\", \"warning\"]\n    text = (x.subject + \" \" + x.body).lower()\n    return PHISHING if any(w in text for w in urgent) else ABSTAIN\n\n# Financial bait keywords\n@labeling_function()\ndef lf_money_keywords(x):\n    money = [\"free\", \"win\", \"won\", \"prize\", \"cash\", \"reward\", \"voucher\", \"gift card\", \"claim\"]\n    text = (x.subject + \" \" + x.body).lower()\n    return PHISHING if any(w in text for w in money) else ABSTAIN\n\n# Account/credential harvesting language\n@labeling_function()\ndef lf_credential_keywords(x):\n    creds = [\"verify\", \"confirm your\", \"account number\", \"bank details\", \"card number\", \"password\", \"ssn\"]\n    text = (x.subject + \" \" + x.body).lower()\n    return PHISHING if any(w in text for w in creds) else ABSTAIN\n\n# Legitimate meeting/work references\n@labeling_function()\ndef lf_work_keywords(x):\n    work = [\"meeting\", \"standup\", \"calendar\", \"agenda\", \"onboarding\", \"feedback\", \"invoice\", \"schedule\", \"team\"]\n    text = (x.subject + \" \" + x.body).lower()\n    return LEGITIMATE if any(w in text for w in work) else ABSTAIN",
   "id": "3a5b0c6a06527cb5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### b) Regex-based LFs",
   "id": "20a383fe38a38140"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:27.229535500Z",
     "start_time": "2026-02-24T03:34:27.207142500Z"
    }
   },
   "source": "# Dollar amounts — phishing often baits with specific sums\n@labeling_function()\ndef lf_dollar_amount(x):\n    return PHISHING if re.search(r'\\$[\\d,]+', x.subject + \" \" + x.body) else ABSTAIN\n\n# Suspicious URLs — phishing often uses non-standard domains\n@labeling_function()\ndef lf_suspicious_url(x):\n    return PHISHING if re.search(r'http[s]?://[\\w\\-]+\\.(xyz|biz|info|co|net/)', x.body, re.I) else ABSTAIN\n\n# Legitimate Re:/Fwd: with work context\n@labeling_function()\ndef lf_reply_forward(x):\n    if re.match(r'^(re|fwd|fw):', x.subject, re.I):\n        work_words = [\"contract\", \"review\", \"pr\", \"meeting\", \"documents\", \"proposal\", \"report\", \"salary\"]\n        if any(w in x.body.lower() for w in work_words):\n            return LEGITIMATE\n    return ABSTAIN",
   "id": "2d2af103a9fd96c7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### c) Structural / heuristic LFs",
   "id": "fb695af0f9f5481f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:29.262728500Z",
     "start_time": "2026-02-24T03:34:29.236206300Z"
    }
   },
   "source": "# ALL CAPS words in subject — common spam pattern\n@labeling_function()\ndef lf_caps_subject(x):\n    words = x.subject.split()\n    caps_count = sum(1 for w in words if w.isupper() and len(w) > 2)\n    return PHISHING if caps_count >= 2 else ABSTAIN\n\n# Excessive exclamation marks\n@labeling_function()\ndef lf_exclamation(x):\n    return PHISHING if (x.subject + x.body).count(\"!\") >= 3 else ABSTAIN\n\n# Short, normal-length subject — typical of legitimate email\n@labeling_function()\ndef lf_normal_subject_length(x):\n    word_count = len(x.subject.split())\n    return LEGITIMATE if 3 <= word_count <= 8 else ABSTAIN",
   "id": "2537cc2fc791c3e8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Applying LFs and Analyzing Coverage",
   "id": "462031e3a71ecd88"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:30.689390800Z",
     "start_time": "2026-02-24T03:34:30.649241400Z"
    }
   },
   "source": "lfs = [\n    lf_urgent_keywords,\n    lf_money_keywords,\n    lf_credential_keywords,\n    lf_work_keywords,\n    lf_dollar_amount,\n    lf_suspicious_url,\n    lf_reply_forward,\n    lf_caps_subject,\n    lf_exclamation,\n    lf_normal_subject_length,\n]\n\napplier = PandasLFApplier(lfs=lfs)\nL_train = applier.apply(df=df_train)\nL_test  = applier.apply(df=df_test)",
   "id": "adfa2da1c3f11063",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 12328.42it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 11989.43it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:33.263760600Z",
     "start_time": "2026-02-24T03:34:33.196948800Z"
    }
   },
   "source": "LFAnalysis(L=L_train, lfs=lfs).lf_summary(Y=Y_train_gold)",
   "id": "e809fa493d5777b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NEU\\IE7374_Lab\\.venv\\Lib\\site-packages\\scipy\\sparse\\_construct.py:543: FutureWarning: Input has data type int64, but the output has been cast to float64.  In the future, the output data type will match the input. To avoid this warning, set the `dtype` parameter to `None` to have the output dtype match the input, or set it to the desired output data type.\n",
      "Note: In Python 3.11, this warning can be generated by a call of scipy.sparse.diags(), but the code indicated in the warning message will refer to an internal call of scipy.sparse.diags_array(). If that happens, check your code for the use of diags().\n",
      "  A = diags_array(diagonals, offsets=offsets, shape=shape, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                          j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "lf_urgent_keywords        0      [1]  0.178571  0.178571   0.178571       10   \n",
       "lf_money_keywords         1      [1]  0.214286  0.214286   0.214286        8   \n",
       "lf_credential_keywords    2      [1]  0.232143  0.232143   0.232143       13   \n",
       "lf_work_keywords          3      [0]  0.250000  0.250000   0.035714       13   \n",
       "lf_dollar_amount          4      [1]  0.285714  0.285714   0.285714       14   \n",
       "lf_suspicious_url         5      [1]  0.107143  0.107143   0.107143        6   \n",
       "lf_reply_forward          6      [0]  0.071429  0.071429   0.053571        2   \n",
       "lf_caps_subject           7      [1]  0.053571  0.053571   0.053571        3   \n",
       "lf_exclamation            8      [1]  0.035714  0.035714   0.035714        2   \n",
       "lf_normal_subject_length  9      [0]  1.000000  0.821429   0.589286       28   \n",
       "\n",
       "                          Incorrect  Emp. Acc.  \n",
       "lf_urgent_keywords                0   1.000000  \n",
       "lf_money_keywords                 4   0.666667  \n",
       "lf_credential_keywords            0   1.000000  \n",
       "lf_work_keywords                  1   0.928571  \n",
       "lf_dollar_amount                  2   0.875000  \n",
       "lf_suspicious_url                 0   1.000000  \n",
       "lf_reply_forward                  2   0.500000  \n",
       "lf_caps_subject                   0   1.000000  \n",
       "lf_exclamation                    0   1.000000  \n",
       "lf_normal_subject_length         28   0.500000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_urgent_keywords</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_money_keywords</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_credential_keywords</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_work_keywords</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_dollar_amount</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_suspicious_url</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_reply_forward</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_caps_subject</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_exclamation</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_normal_subject_length</th>\n",
       "      <td>9</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Reading the summary:**\n- **Coverage**: fraction of training points the LF labels (non-abstain)\n- **Overlaps**: fraction of points where this LF and at least one other agree\n- **Conflicts**: fraction of points where this LF and another disagree\n- **Emp. Acc.**: estimated accuracy against the gold labels (only shown when gold labels are provided — in practice we wouldn't have these)",
   "id": "bdd8ad5f1e09ffe0"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:38.688883200Z",
     "start_time": "2026-02-24T03:34:38.584700700Z"
    }
   },
   "source": "import matplotlib.pyplot as plt\n\ndef plot_label_frequency(L, title=\"\"):\n    counts = (L != ABSTAIN).sum(axis=1)\n    plt.figure(figsize=(7, 4))\n    plt.hist(counts, bins=range(L.shape[1] + 1), edgecolor='black', color='steelblue', align='left')\n    plt.xlabel(\"Number of LF votes per email\")\n    plt.ylabel(\"Count\")\n    plt.title(title or \"LF vote distribution\")\n    plt.xticks(range(L.shape[1]))\n    plt.tight_layout()\n    plt.show()\n\nplot_label_frequency(L_train, \"How many LFs vote on each training email\")",
   "id": "cf2e5061719d84f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Combining LF Votes with the Label Model\n\nA simple majority vote treats all LFs equally. Snorkel's `LabelModel` is smarter — it estimates each LF's accuracy and learns correlations between them, producing a better set of probabilistic labels.",
   "id": "24cf8df9abb89eef"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:42.654458Z",
     "start_time": "2026-02-24T03:34:40.767358800Z"
    }
   },
   "source": "from snorkel.labeling.model import MajorityLabelVoter, LabelModel\n\n# Baseline: majority vote\nmajority_model = MajorityLabelVoter(cardinality=2)\npreds_majority = majority_model.predict(L=L_test)\nmajority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\"accuracy\"]\nprint(f\"Majority vote accuracy: {majority_acc * 100:.1f}%\")",
   "id": "ac51c3d17a4c327a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority vote accuracy: 87.5%\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:43.905591100Z",
     "start_time": "2026-02-24T03:34:42.657454700Z"
    }
   },
   "source": "# Label Model: learns LF weights and correlations\nlabel_model = LabelModel(cardinality=2, verbose=True)\nlabel_model.fit(L_train=L_train, n_epochs=300, log_freq=100, seed=42)\n\nlabel_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\"accuracy\"]\nprint(f\"Label Model accuracy:  {label_model_acc * 100:.1f}%\")",
   "id": "8bfcf89fc7816b02",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/300 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=1.484]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.027]\n",
      " 56%|█████▌    | 168/300 [00:00<00:00, 1671.41epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.022]\n",
      "100%|██████████| 300/300 [00:00<00:00, 1941.57epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Model accuracy:  83.3%\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Training a Downstream Classifier\n\nThe `LabelModel` produces probabilistic labels for the unlabeled training set. We now use these as training labels for a `LogisticRegression` classifier on bag-of-words features — this classifier can generalize beyond the LF heuristics to unseen patterns.",
   "id": "43afa0df638252c5"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:46.330172200Z",
     "start_time": "2026-02-24T03:34:46.257358Z"
    }
   },
   "source": "from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Generate probabilistic labels for training set from the Label Model\nprobs_train = label_model.predict_proba(L=L_train)\npreds_train  = label_model.predict(L=L_train, tie_break_policy=\"random\")\n\n# Bag-of-words features on subject + body\ndf_train[\"text\"] = df_train[\"subject\"] + \" \" + df_train[\"body\"]\ndf_test[\"text\"]  = df_test[\"subject\"]  + \" \" + df_test[\"body\"]\n\nvectorizer = CountVectorizer(ngram_range=(1, 2), min_df=1)\nX_train = vectorizer.fit_transform(df_train[\"text\"])\nX_test  = vectorizer.transform(df_test[\"text\"])",
   "id": "e5c5226a4034755f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T03:34:54.005328400Z",
     "start_time": "2026-02-24T03:34:53.957012200Z"
    }
   },
   "source": "clf = LogisticRegression(C=1.0, solver=\"liblinear\", random_state=42)\nclf.fit(X_train, preds_train)\n\npreds_clf = clf.predict(X_test)\nclf_acc = accuracy_score(Y_test, preds_clf)\n\nprint(f\"Logistic Regression (LabelModel labels) accuracy: {clf_acc * 100:.1f}%\")\nprint()\nprint(classification_report(Y_test, preds_clf, target_names=[\"LEGITIMATE\", \"PHISHING\"]))",
   "id": "f2055fef226cc7d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (LabelModel labels) accuracy: 79.2%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  LEGITIMATE       0.89      0.67      0.76        12\n",
      "    PHISHING       0.73      0.92      0.81        12\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.81      0.79      0.79        24\n",
      "weighted avg       0.81      0.79      0.79        24\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n| Method | Test Accuracy |\n|---|---|\n| Majority Vote | see above |\n| Label Model | see above |\n| Logistic Regression (LM labels) | see above |\n\n**Key takeaways:**\n- We labeled the entire training set programmatically — no manual annotation\n- LFs have varied coverage and accuracy; the Label Model accounts for this\n- The downstream classifier generalizes beyond the LF rules to new phishing patterns\n- In practice the LF rules would be refined iteratively as you see errors",
   "id": "e878b943c66a5571"
  }
 ]
}
